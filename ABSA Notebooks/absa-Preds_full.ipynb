{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABSA on Preds Threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install clean-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load libraries\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.chains import SequentialChain\n",
    "import openai\n",
    "from getpass import getpass\n",
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import cleantext\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data\n",
    "preds_posts = pd.read_csv('../Reddit Data/preds_posts_clean.csv')\n",
    "preds_comments = pd.read_csv('../Reddit Data/preds_comments_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load helper functions\n",
    "class Post:\n",
    "    def __init__(self, post_id, title, content):\n",
    "        self.post_id = post_id\n",
    "        self.title = title\n",
    "        self.content = content\n",
    "        self.comments = []\n",
    "\n",
    "class Comment:\n",
    "    def __init__(self, comment_id, text, post_id):\n",
    "        self.comment_id = comment_id\n",
    "        self.text = text\n",
    "        self.post_id = post_id  # Store the post_id\n",
    "        self.parent_comment = None\n",
    "        self.replies = []\n",
    "\n",
    "# Create dictionaries to map post IDs to Post objects and comment IDs to Comment objects.\n",
    "posts_dict = {}\n",
    "comments_dict = {}\n",
    "\n",
    "# Populate posts_dict and comments_dict from your dataframes.\n",
    "for post_row in preds_posts.itertuples():\n",
    "    post_id = post_row.id\n",
    "    title = post_row.Title\n",
    "    content = post_row.Content\n",
    "    post = Post(post_id, title, content)\n",
    "    posts_dict[post_id] = post\n",
    "\n",
    "\n",
    "comments_df = preds_comments.rename(columns={\n",
    "    'Comment ID': 'Comment_ID',\n",
    "    'Parent Comment ID': 'Parent_Comment_ID',\n",
    "    'Text': 'Text',\n",
    "    'Author': 'Author',\n",
    "    'Date': 'Date',\n",
    "    'Post ID': 'Post_ID'\n",
    "})\n",
    "\n",
    "# Now the columns have underscores instead of spaces, making it easier to access them.\n",
    "\n",
    "# You can use the updated column names directly in your code as follows:\n",
    "for comment_row in comments_df.itertuples():\n",
    "    comment_id = comment_row.Comment_ID\n",
    "    text = comment_row.Text\n",
    "    post_id = comment_row.Post_ID  # Store the post_id\n",
    "    comment = Comment(comment_id, text, post_id)\n",
    "    comments_dict[comment_id] = comment\n",
    "\n",
    "    # Assign parent comment if it exists.\n",
    "    parent_comment_id = comment_row.Parent_Comment_ID\n",
    "    if not pd.isna(parent_comment_id):\n",
    "        parent_comment = comments_dict.get(parent_comment_id)\n",
    "        if parent_comment:\n",
    "            comment.parent_comment = parent_comment\n",
    "            parent_comment.replies.append(comment)\n",
    "\n",
    "# Function to get the full thread for a given post and its comments\n",
    "def get_thread_for_post(post, comments_dict):\n",
    "    thread = f\"Title: {post.title}\\nContent: {post.content}\\n\\nComments:\\n\"\n",
    "    \n",
    "    for comment_id, comment in comments_dict.items():\n",
    "        if comment.post_id == post.post_id:\n",
    "            if comment.parent_comment is None:\n",
    "                indicator = \"T:\"  # Top-level comment indicator\n",
    "            else:\n",
    "                indicator = \"R:\"  # Reply indicator\n",
    "            # Add the comment to the thread\n",
    "            thread += f\"{indicator} Comment Text: {comment.text}\\n\"\n",
    "            \n",
    "    thread_no_urls = cleantext.replace_urls(thread, replace_with=\"<URL>\")\n",
    "    return thread_no_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up OpenAI Key\n",
    "OPENAI_API_KEY = getpass()\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo-1106\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEWER EXAMPLES\n",
    "## Aspect Extraction Chain\n",
    "examples = [{\n",
    "    \"thread\": '''\n",
    "    Title: the lack of fundamentals on this team is astounding\n",
    "    Content: to me the most shocking thing is how bad this team is top to bottom when it comes to fundamentals. awful decision making, penalties, etc. we’re awful across the board. it’s one thing to not have much talent, but how could a team under Brunette be so bad at the fundamentals? our older teams had great fundamentals. \n",
    "    \n",
    "    what happened? this season had really put Brunette's actual coaching skills in a terrible light imo.\n",
    "    Comments: \n",
    "    T: Comment Text: It starts with coaching and buy in. Brunette has lost most of the team IMO. They have no real leaders. Most guys will be gone in 2 years and they know it. A bunch of rouge players not giving a shit.\n",
    "\n",
    "    They don't trust the Brunette way anymore.\n",
    "    R: Comment Text: Moulin Rouge?\n",
    "    T: Comment Text: There is nowhere else to look other than Brunette. The justification to keep him around is that he should be able to field a disciplined team that gives effort and makes smart plays even if there is a talent disparity.\n",
    "\n",
    "    With how unprofessional and unprepared the team has been the last few years I’m not sure what coaching “advantage” he’s giving you anymore.\n",
    "    R: Comment Text: Trotz has to get rid of Brunette. Period\n",
    "    R: Comment Text: It's time. 2-7.\n",
    "\n",
    "    Who can this team beat in the remaining schedule? The Sharks??\n",
    "    ''',\n",
    "    \"aspects\": \"Relevant aspects are 'team performance', 'coaching and management'\"\n",
    "},\n",
    "{\n",
    "    \"thread\": '''\n",
    "    Title: Am I the only one that thinks espn hates talking abt the preds\n",
    "    Content:  I swear they talk abt everyone we beat and any other game that was on or abt to play rather than giving us any credit. From what I’ve seen they don’t want us here and they try to play down what we’ve done and have given us no credit saying that the teams we’ve beat didn’t play good or we got lucky. Let me know your thoughts\n",
    "    Comments: \n",
    "    T: Surprise! We are a small market team. It’s been this way literally forever.\n",
    "    R: How is Nashville a small market team when there are 1.5 million people in the city on any given day?\n",
    "    R: Because half of them aren’t fans/from Nashville\n",
    "    T: I think Brunette went over to ESPN and bullied them all to keep the talking about us to a minimum, to help our boys stay focused and keep that hungry underdog mentality!\n",
    "    T: I just enjoy that they are talking. And I don’t think they “hate” us. Just a small market team. Hard to satisfy a national audience with a small amount of fans. They love Forsberg and the heart of the team.\n",
    "    T: ESPN is a known bias propagandizing network . I've switched to fox more and more this year. They giving preds love.\n",
    "    T: People need to understand the audience isn’t the same for ESPN anymore. Its not like it used to be where every man in the world watches ESPN. A lot of the higher quality viewers are just using the internet or their phones now to look up high lights. As a result I feel these sports shows have to be more entertaining to get ratings, and as a result they just talk about the popular teams. People this is entertainment. They aren’t out here to give a fair or honest assessment.\n",
    "    R: Chicken and egg with that one. I stopped watching when ESPN became the Lebron/Tiger/Brady channel.\n",
    "    ''',\n",
    "    \"aspects\": \"Relevant aspects are 'media coverage'\"\n",
    "},\n",
    "{\n",
    "   \"thread\": '''\n",
    "    Title: Flyers Fans visiting the area looking for the best meal in Bridgestone Arena\n",
    "    Content:  Hey all, me and a bunch of friends are visiting Nashville for a bachelor party and surprising the married man to be with tickets to the game Sunday. Seeing as we're probably gonna be hungover on death's door, what's the best meal to munch on in Bridgestone?\n",
    "    \n",
    "    If you can drop a name and the section in the comments I'll love you forever.\n",
    "    Comments: \n",
    "    T: I don’t care what anyone says, the walking taco bowl down near the main entrance always slaps. Especially if you’re a couple beers deep.\n",
    "    T: If you’re dead set on eating at Bridgestone the BBQ nachos are my guilty pleasure.\n",
    "    T: The grilled cheese sandwiches (Ground floor, just off to the left of the entrance) absolutely fucking slap. I would get one right away as they can take a while, but god damn are they good.\n",
    "    ''',\n",
    "    \"aspects\": \"Relevant aspects are 'stadium amenities'\"\n",
    "},\n",
    "{\n",
    "    \"thread\": '''\n",
    "    Title: Make Bridgestone loud again!\n",
    "    Content:  This is a call to arms for all fans going to the game tonight! I know things have looked bleak as of late, but we need to remind our boys of our support, and that they shouldn’t dread playing at home for us!\n",
    "    \n",
    "    So even if we get into a big hole, let’s all band together and be leaders in the crowd tonight and cheer our team into a win! Never give up!\n",
    "    Comments: \n",
    "    T: When they jacked up the prices the crowd noise quieted down immediately. There was a precipitous drop the season after the playoff run.\n",
    "    R: Prices were going up after the playoff run anyway. The only question was whether the increase would go to the Predators or to the ticket brokers.\n",
    "    T: Ridiculously expensive tickets have kept the most loyal and loudest fans home.\n",
    "    T: I was literally sitting at Wicked Weed watching the prices fall as we got closer to game time because I was having this exact conversation. It’s not the first time the tickets have hit $10. I posted a screenshot with a $10 lower bowl pair a couple weeks ago.\n",
    "    R: $10 lower bowl seats? PM me if you ever see that again lol\n",
    "    R: $20 lower bowl seats tonight. $10 in the upper bowl. Shame all the real fans are being priced out though.\n",
    "    ''',\n",
    "    \"aspects\": \"Relevant aspects are 'stadium atmosphere', 'pricing'\"\n",
    "}]\n",
    "\n",
    "prompt_template = '''\n",
    "Thread: {thread}\n",
    "{aspects}\n",
    "'''\n",
    "\n",
    "example_prompt = PromptTemplate(input_variables = [\"thread\", \"aspects\"], template = prompt_template)\n",
    "\n",
    "final_prompt = FewShotPromptTemplate(\n",
    "    examples = examples,\n",
    "    example_prompt = example_prompt,\n",
    "    suffix = \"Thread: {thread}\\n\",\n",
    "    input_variables = [\"thread\"],\n",
    "    prefix = '''\n",
    "    I am extracting aspects from a Reddit Thread made by Nashville Predators fans. The Nashville Predators are a hockey team that play at their stadium: Bridgestone Arena in Nashville, Tennessee. Their coach is Andrew Brunette, their general manager is Barry Trotz, and some of their key players are Juuce Saros, Roman Josi, Ryan O'Reilly, Filip Forsberg, Tyson Barrie, Alexandre Carrier, Jeremy Lauzon, Colton Sissons, Kevin Lankinen, Cole Smith, Kiefer Sherwood, Ryan McDonagh, and Gustav Nyquist. Any other names that are given, assume they are on an opposing team.\n",
    "    For this conversational thread, please return a list of the following aspects of fan experience that are present in the thread: 'team performance' (specifically the Predators, ignore discussion about other teams), 'stadium amenities' (including food and the gift shop), 'coaching and management', 'pricing', 'stadium atmosphere' (including comfort, safety, and crowd atmosphere), 'media coverage', and a 'miscellaneous' category. The 'miscellaneous' category should be returned if there is general conversation that is not covered by the other aspects.\n",
    "    The structure of the post will be as follows: Title is the general title made of the original post. Content is the text from the original post. Comments will be all comments on the post. Any comment labelled as \"T: Comment Text\" is a top-level comment, so use the original post and content as the context for this comment. Any comment labelled as \"R: Comment Text\" is a reply comment, so use all the comments above it until you hit a top-level comment, as well as the original post and content as the context for this comment. If the Content of a post is \"nan\", that means the post was an image. For any of these posts, just consider the post title and comments, ignoring the \"nan\" content.\n",
    "    ''')\n",
    "\n",
    "aspect_extraction_chain = LLMChain(llm = llm, prompt = final_prompt, output_key = 'aspects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sentiment Analysis Chain\n",
    "prompt_template2 = '''\n",
    "The following text is a Reddit thread and the list of aspects extracted from that thread. The aspects will be in the format ['aspect1', 'aspect2'...]. For each aspect in the list, return a sentiment score. Do NOT create aspects of your own; only calculate scores for the aspects provided. This sentiment score should be on a continuous scale from -1 to 1, where -1 is the most negative sentiment, 1 represents the most postive sentiment, and relatively neutral sentiments fall in the range -0.3 to 0.3. Round the score to 2 decimal places. Your output should follow this format: [(Aspect1, Sentiment_Score_1), (Aspect2, Sentiment_Score_2),.....].\n",
    "Thread: {thread}\n",
    "Aspects: {aspects}\n",
    "[(Aspect1, Sentiment_Score_1), (Aspect2, Sentiment_Score_2),.....]\n",
    "'''\n",
    "\n",
    "example_prompt2 = PromptTemplate(input_variables = [\"thread\", \"aspects\"], template = prompt_template2)\n",
    "\n",
    "aspect_sentiment_chain = LLMChain(llm = llm, prompt = example_prompt2, output_key = \"Aspects_with_sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Full Sequential Chain\n",
    "overall_chain = SequentialChain(\n",
    "    chains = [aspect_extraction_chain, aspect_sentiment_chain],\n",
    "    input_variables = [\"thread\"],\n",
    "    output_variables = [\"thread\", \"aspects\", \"Aspects_with_sentiment\"],\n",
    "    verbose = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Store threads\n",
    "threads = []\n",
    "for post_id, post in posts_dict.items():\n",
    "    thread = get_thread_for_post(post, comments_dict)\n",
    "    threads.append(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "## Run on threads\n",
    "## Note: won't store in output, need to learn how to store on to DF\n",
    "for thread in threads:\n",
    "    if i % 5 == 0:\n",
    "        time.sleep(60)\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    res = overall_chain({\"thread\": thread})\n",
    "    temp = res[\"Aspects_with_sentiment\"]\n",
    "    matches = re.findall(r'\\(([^,]+), ([^)]+)\\)', temp)\n",
    "    result_list = [(match[0], float(match[1])) for match in matches]\n",
    "    output.append(result_list)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Storing results\n",
    "ex = preds_posts\n",
    "ex['results'] = output\n",
    "\n",
    "# Replace any quotation marks and force all lowercase\n",
    "ex['cleaned_results'] = ex['results'].apply(lambda x: [(aspect.lower().replace(\"'\", \"\").replace('\"', ''), sentiment) for aspect, sentiment in x])\n",
    "\n",
    "# List of aspects we want to find\n",
    "valid_aspects = ['team performance', 'miscellaneous', 'coaching and management', 'stadium atmosphere', 'pricing', 'stadium amenities', 'media coverage']\n",
    "\n",
    "# Filter the 'cleaned_results' column based on the list of valid aspects\n",
    "junk = ex['cleaned_results'].apply(lambda x: [(aspect, sentiment) for aspect, sentiment in x if aspect not in valid_aspects])\n",
    "ex['cleaned_results'] = ex['cleaned_results'].apply(lambda x: [(aspect, sentiment) for aspect, sentiment in x if aspect in valid_aspects])\n",
    "\n",
    "# Remove any empty lists\n",
    "ex = ex[ex['cleaned_results'].apply(lambda x: len(x) > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned_results\n",
      "team performance           15\n",
      "miscellaneous              12\n",
      "coaching and management     8\n",
      "stadium atmosphere          7\n",
      "pricing                     4\n",
      "stadium amenities           3\n",
      "media coverage              3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Distribution of aspects\n",
    "aspect_counts = ex['cleaned_results'].explode().apply(lambda x: x[0]).value_counts()\n",
    "\n",
    "# Display the aspect counts\n",
    "print(aspect_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect\n",
      "coaching and management   -0.051250\n",
      "media coverage             0.080000\n",
      "miscellaneous              0.073333\n",
      "pricing                   -0.137500\n",
      "stadium amenities          0.120000\n",
      "stadium atmosphere         0.160000\n",
      "team performance           0.151333\n",
      "Name: sentiment, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Averaging sentiment scores\n",
    "# Explode the 'cleaned_results' column to have one row for each aspect-sentiment pair\n",
    "df_exploded = ex.explode('cleaned_results')\n",
    "\n",
    "# Extract aspect and sentiment into separate columns\n",
    "df_exploded[['aspect', 'sentiment']] = pd.DataFrame(df_exploded['cleaned_results'].tolist(), index=df_exploded.index)\n",
    "\n",
    "# Calculate the average sentiment score for each aspect\n",
    "average_sentiment = df_exploded.groupby('aspect')['sentiment'].mean()\n",
    "\n",
    "# Display the average sentiment scores\n",
    "print(average_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                []\n",
       "1                                []\n",
       "2                                []\n",
       "3                                []\n",
       "4                                []\n",
       "5                                []\n",
       "6                                []\n",
       "7                                []\n",
       "8                                []\n",
       "9                                []\n",
       "10                               []\n",
       "11                               []\n",
       "12                               []\n",
       "13                               []\n",
       "14                               []\n",
       "15                               []\n",
       "16                               []\n",
       "17                               []\n",
       "18                               []\n",
       "19                               []\n",
       "20                               []\n",
       "21                               []\n",
       "22                               []\n",
       "23    [(trade negotiations, -0.02)]\n",
       "24                               []\n",
       "Name: cleaned_results, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "junk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "5206b32b5f345ee646df70bcbe011cac435e70d5fa1022839ac50730ea7455ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
